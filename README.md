GMM-HMMを実装し、10単語の孤立単語音声認識の実験を行う
以下の流れでおこなっていく。

1 音素リストとラベルの準備
2 音素HMMの定義と初期化
3 単峰の正規分布を用いたHMMの学習
4 GMM-HMMの学習
5 評価データの作成
6 SGM-HMMおよびGMM-HMMでの孤立単語音声認識
7 音素アライメントの推定


【事前準備】
まず、"data"や"00prepare"のフォルダと同じ階層に"03gmm_hmm"というフォルダを作成する。
今後、紹介するソースコードは"03gmm_hmm"フォルダ内で実行することを想定している。

※"./phone.txt"には音素のリストが記されたものとなっているのだが、事前に手動で作成しておく。


【実行手順】
"00make_label.py"⇨"hmmfunc.py"⇨"01_make_proto.py"⇨"02_init_hmm.py"⇨"03_train_sgmhmm.py"⇨"03_train_gmmhmm.py"⇨
"04_prepare_testdata.py"⇨"05_compute_feat_test.py"⇨"06_recognize.py"⇨"07_phone_alignment"


【コード解説】
"00make_label.py"
音素の表記を文字から数値に変換するソースコード。

ポーズ(無音)を表す記号は"slience_phone = 'pau'"にて定義されている。まず、"pau"を音素リスト"phone_list"に加え、次に"./phone.txt"の上から"N"、"a"、"b"・・・、と順番に加えていく。
このリストに加えられた順番が、各音素表記の文字に対する数値となる。すなわち、"pau"は"0"、"N"は"1"、"a"は"2"、・・・、となる。この対応表記を"./exp/data/train_small/phone_list"に記録している。
この文字と数値の対応関係をもとに"./data/label/train_small/text_phone"を読み込んで、各音素の文字を数値に変換し"./exp/data/train_small/text_int"というファイルに書き込む。
この処理は"phone_to_int"関数内で行われている。この時、各音声ファイルの最初と最後には必ず無音が存在していると仮定し、ラベルの最初と最後に"0"(="pau")を挿入した上で、"text_int"に書き込む。
各発話IDの音素列が数値に変換され、かつ両端に"0"が挿入されたラベルファイルが作成できる。このファイルをHMMを学習する際の正解ラベルとして使用していく。


"hmmfunc.py"  1
MonoPhoneHMMクラスのコンストラクタ部のソースコード。
"MonoPhoneHMM"というクラスを定義し、HMMに関する変数や処理全般をこのクラスに実装していく。

コンストラクタ部では、変数の定義を行なっている。一般にHMMは音素ごとに異なる状態数のHMMを定義してもよく、状態ごとに異なるGMMの混合数を定義しても良い。
ただし、今ソースコードでは簡単なため全ての音素で状態数は"num_states"で統一している。また、全ての状態においてGMMの混合数は"num_mixture"で統一している。


"hmmfunc.py"  ２
MonoPhoneHMMクラスのプロトタイプの作成するソースコード。
HMMプロトタイプの設定値が定義されている。

このコードの"make_proto"関数では、引数に入力された音素リスト、HMM状態数、自己ループ確率、入力特徴量の次元数を内部変数にセットする。また、GMMの混合数も1に設定する。設定変数をセットした後、
各状態の正規分布を作成する。音素p、状態s、混合要素mの正規分布は変数"pdf[p][s][m]"という形で定義される。また"pdf[p][s][m]"の中身は"gaussian = 'weight','mu','var','gConst'"という
四つのキーを持つ辞書形の変数で定義されている。


"01_make_proto.py"
このコードでは各音素HMMの状態数は3としている。音声特徴量は13次元のMFCC特徴量を使用するため、HMMの入力特徴量"num_dims"は13としている。また、HMMの遷移確立の初期値も設定している。
ここでは、全ての音素p、状態iにおいて、自己ループの確率は0.7としている。本コードでは、最初にSGM-HMMを学習し、その結果を利用してGMM-HMMを作成していく。
設定が終わると"./exp/data/train_small/phone_list"から、音素のリストを読み込む。そして、MonoPhoneHMMクラスの"make_proto"関数を実行し、HMMプロトタイプを作成する。
その後、"save_hmm"関数を実行して、作成したHMMプロトタイプを保存する。


"hmmfunc.py"  3
MonoPhoneHMMクラスのフラットスタートによりパラメータを初期化する関数。


"02_init_hmm.py"
パラメータ初期化部とHMMファイルのソースコード。
事前に求めた特徴量の平均と標準偏差が記述されたファイル"mean_std.txt"を開き、次元ごとの平均値"mean"と標準偏差"std"を読み込む。
そして標準偏差を２乗して分散"var"を得る。次にMonoPhoneHMMクラスの"load_hmm"関数を用いて"hmmproto"　ファイルを読み込む。その後、"flat_init"関数を、平均値と分散値を引数として実行する。
この時パラメータが変わってしまうため、"gConst"を再計算する。そしてHMMのパラメータを初期化した後"save_hmm"関数を用いて"./exp/model_3state_1mix/0.hmm"というファイルに保存する。


"03_train_sgmhmm.py"
初期化モデルに対してパラメータの最適化、つまりSGM-HMMの学習を行うソースコード。
このコードでは学習データとして、"01compute_features/mfcc/train_small/feat.scp"を使用する。このサブセットには1,000発話の音声が含まれている。

まず、初期化したHMMファイル"0.hmm"を"load_hmm"に読み込ませる。次に各発話IDに対する音素ラベル(数値表記)を読み込み"label_list"に格納する。その後"feats.scp"のうち先頭の50行のみを読み込み、
そこに掲載されている特徴量ファイルのパスを"feat_list"に格納する。特徴量ファイルのリストとラベルのリストを用意したら"train"関数を実行し、HMMのパラメータ更新を行う。
ここでは、同じ処理を複数回繰り返すため、"train"関数を"num_iter"の数だけforループを繰り返す。本ソースコードでは"num_iter = 10"とする。また、更新のたびに"[更新回数].hmm"というファイル名で途中結果を保存する。


"hmmfunc.py"  4
実際に学習処理を行なっている"train"関数に関わるソースコード。
ここでは、"calc_out_prob"、"calc_alpha"、"calc_beta"、"update_accumulators"の関数を各発話に対して実行していく。全発話に対して処理が終わると、"update_parameters"を実行する。


"03_train_gmmhmm.py"
GMM-HMMを学習させるソースコード。
このコードは"03_train_sgmhmm.py"と同じようになっている。

混合数を倍増する処理を何回行うかを"mixup_time"で設定する。本ソースコードでは"mixup_time=1"としているので、混合数は2となる。"mixup_time"を2にすると、混合数は4というように、混合数は2のべき乗になる。
学習を行う部分では、まずSGM-HMMを"num_iter"の回数だけ更新する。その後"mixup"関数を実行し、混合数2のGMM-HMMの初期値を作成する。そして、再度"num_iter"の回数だけ更新し、GMM-HMMを学習する。
最終的に混合数2で10回更新したGMM-HMMが"10.hmm"に出力される。


"04_prepare_testdata.py"
音声認識に必要なテストデータを作成するソースコード。
このソースコードでは、"COUNTERSUFFIX26_01wav"を16,000Hzにダウンサンプリングした後「一つ」〜「とお」までの10単語を切り出して保存するとともに、保存したwavファイル名を記述したリストファイル"./exp/data/test/wax.scp"
を作成する。さらに評価データに対する正解ラベルを"text_int"に出力する。これは音素アライメントの実験において使用する。


"05_compute_feat_test.py"
切り出した評価wavデータに対して、MFCC特徴量を抽出する。ソースコードは"01_compute_mfcc.py"と一緒である。


"06_recognize.py"
孤立単語音声認識を実行するソースコード。
"phone_list"を開き、音素の文字と数値の対応リストを得る。次に、先ほど作成された発話辞書"lexicon.txt"を開く。これには、単語ごとの音素列が定義されているが、音素の文字で表記されているため、音素・数値の対応リストを
使用して文字表記から数値表記にする。そして変数"lexicon"に単語、音素列(文字表記)、音素列(数字表記)の組みを単語ごとに追加していく。
その後、HMMファイルを作成する。ファイルを読み込んだ後各評価データのMFCC特徴量を読み込み、"recognize"関数を実行することで、音声認識を行う。"recognize"関数では、発話辞書に登録されている10単語の中で、
最も尤度が高かった単語を"result"に、尤度が高い順にランキングした結果を"detail"に出力する。


"07_phone_alignment"
音声アライメントの推定を行うソースコード。
事前に作成した評価データの正解ラベル"text_int"を読み込む。その後評価データの特徴量リスト"feats.scp"を読み込む。

このソースコードでは、10個の評価データのうち発話IDが"7"の音声を発話している音声を評価する。発話ID"7"の特徴量"feat"と、そのラベル"label"を引数として"phone_alignment"関数を実行することで、
音素アライメント推定結果"alignment"を得る。
